{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Creación de Nuevas Variables - Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from pyspark import SparkContext\n",
    "#sc = SparkContext()\n",
    "#from pyspark.sql import SQLContext\n",
    "#sqlContext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bd5 = sqlContext.read.format(\n",
    "    \"com.databricks.spark.csv\"\n",
    ").option(\"header\", \"true\").load(\"bd5.csv\", inferSchema=True)\n",
    "sqlContext.registerDataFrameAsTable(bd5, \"bd5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bd5 = bd5.withColumn('Horario1',(bd5.Horario==1) \n",
    ").withColumn('Horario2',(bd5.Horario==2) \n",
    ").withColumn('Horario3',(bd5.Horario==3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables Discretizadas Binarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(YEAR=2016, MONTH=12, DAY_OF_MONTH=1, DAY_OF_WEEK=4, CRS_DEP_TIME=1440, OP_UNIQUE_CARRIER='AA', TAIL_NUM='N011AA', ARR_DELAY=-19.0, DEP_DELAY=-8.0, ORIGIN='LAS', DEST='LAX', DISTANCE=236.0, CANCELLED=0.0, DIVERTED=0.0, CARRIER_DELAY=0.0, WEATHER_DELAY=0.0, NAS_DELAY=0.0, SECURITY_DELAY=0.0, LATE_AIRCRAFT_DELAY=0.0, LogD=2.3729120029701067, Retraso=0, RetrasoNeto=-11.0, Horario=3, Horario1=False, Horario2=False, Horario3=True, SalidaBin=0.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import Binarizer\n",
    "\n",
    "binarizer = Binarizer(threshold=15.0, inputCol='DEP_DELAY', outputCol='SalidaBin')\n",
    "binarizer.transform(bd5).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|DEP_DELAY|SalidaBin|\n",
      "+---------+---------+\n",
      "|     -8.0|      0.0|\n",
      "|      6.0|      0.0|\n",
      "|     -5.0|      0.0|\n",
      "|     -6.0|      0.0|\n",
      "|     -5.0|      0.0|\n",
      "|     -5.0|      0.0|\n",
      "|     -8.0|      0.0|\n",
      "|     -6.0|      0.0|\n",
      "|     -3.0|      0.0|\n",
      "|     -6.0|      0.0|\n",
      "|    -11.0|      0.0|\n",
      "|      0.0|      0.0|\n",
      "|      1.0|      0.0|\n",
      "|      2.0|      0.0|\n",
      "|     -9.0|      0.0|\n",
      "|      5.0|      0.0|\n",
      "|      7.0|      0.0|\n",
      "|     -4.0|      0.0|\n",
      "|     -2.0|      0.0|\n",
      "|     -7.0|      0.0|\n",
      "+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binarizer.transform(bd5).select('DEP_DELAY','SalidaBin').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables Discretizadas en Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|DEP_DELAY|SalidaCat|\n",
      "+---------+---------+\n",
      "|     -8.0|      0.0|\n",
      "|      6.0|      1.0|\n",
      "|     -5.0|      0.0|\n",
      "|     -6.0|      0.0|\n",
      "|     -5.0|      0.0|\n",
      "|     -5.0|      0.0|\n",
      "|     -8.0|      0.0|\n",
      "|     -6.0|      0.0|\n",
      "|     -3.0|      0.0|\n",
      "|     -6.0|      0.0|\n",
      "|    -11.0|      0.0|\n",
      "|      0.0|      1.0|\n",
      "|      1.0|      1.0|\n",
      "|      2.0|      1.0|\n",
      "|     -9.0|      0.0|\n",
      "|      5.0|      1.0|\n",
      "|      7.0|      1.0|\n",
      "|     -4.0|      0.0|\n",
      "|     -2.0|      0.0|\n",
      "|     -7.0|      0.0|\n",
      "+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Bucketizer\n",
    "bucketizer = Bucketizer(splits=[-float(\"inf\"), 0.0, 15.0, float(\"inf\")],\n",
    "                        inputCol='DEP_DELAY', outputCol='SalidaCat')\n",
    "bucketizer.transform(bd5).select('DEP_DELAY','SalidaCat').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versiones más nuevas de Pyspark incluyen otras transformaciones, por ejemplo QuantileDiscretizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expansión polinómica de Variables \n",
    "(términos cuadráticos, productos, etc.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DEP_DELAY=-8.0, DISTANCE=236.0, Polyn=DenseVector([-8.0, 64.0, 236.0, -1888.0, 55696.0])),\n",
       " Row(DEP_DELAY=6.0, DISTANCE=236.0, Polyn=DenseVector([6.0, 36.0, 236.0, 1416.0, 55696.0])),\n",
       " Row(DEP_DELAY=-5.0, DISTANCE=236.0, Polyn=DenseVector([-5.0, 25.0, 236.0, -1180.0, 55696.0])),\n",
       " Row(DEP_DELAY=-6.0, DISTANCE=236.0, Polyn=DenseVector([-6.0, 36.0, 236.0, -1416.0, 55696.0])),\n",
       " Row(DEP_DELAY=-5.0, DISTANCE=651.0, Polyn=DenseVector([-5.0, 25.0, 651.0, -3255.0, 423801.0]))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import PolynomialExpansion\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['DEP_DELAY','DISTANCE'],\n",
    "    outputCol='features')\n",
    "\n",
    "px = PolynomialExpansion(\n",
    "    degree=2, \n",
    "    inputCol=\"features\", \n",
    "    outputCol=\"Polyn\")\n",
    "\n",
    "bd6 = px.transform(assembler.transform(bd5))\n",
    "\n",
    "bd6.select('DEP_DELAY','DISTANCE','Polyn').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estandarización de las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n",
      "|     features|         stdfeatures|\n",
      "+-------------+--------------------+\n",
      "| [-8.0,236.0]|[-0.5061531206197...|\n",
      "|  [6.0,236.0]|[-0.2251841350618...|\n",
      "| [-5.0,236.0]|[-0.4459454808573...|\n",
      "| [-6.0,236.0]|[-0.4660146941114...|\n",
      "| [-5.0,651.0]|[-0.4459454808573...|\n",
      "| [-5.0,370.0]|[-0.4459454808573...|\n",
      "| [-8.0,868.0]|[-0.5061531206197...|\n",
      "|[-6.0,1464.0]|[-0.4660146941114...|\n",
      "|[-3.0,1464.0]|[-0.4058070543490...|\n",
      "|[-6.0,1055.0]|[-0.4660146941114...|\n",
      "|[-11.0,255.0]|[-0.5663607603821...|\n",
      "| [0.0,1440.0]|[-0.3455994145866...|\n",
      "|  [1.0,641.0]|[-0.3255302013325...|\n",
      "| [2.0,1440.0]|[-0.3054609880783...|\n",
      "|[-9.0,1055.0]|[-0.5262223338738...|\n",
      "| [5.0,1055.0]|[-0.2452533483159...|\n",
      "|  [7.0,370.0]|[-0.2051149218077...|\n",
      "|[-4.0,1055.0]|[-0.4258762676032...|\n",
      "|[-2.0,1055.0]|[-0.3857378410949...|\n",
      "|[-7.0,1464.0]|[-0.4860839073656...|\n",
      "+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"stdfeatures\",\n",
    "                        withStd=True, withMean=True)\n",
    "scalerModel = scaler.fit(bd6)\n",
    "bd6std = scalerModel.transform(bd6)\n",
    "\n",
    "bd6std.select('features','stdfeatures').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tranformación manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bd7 = bd6.withColumn('DepDelay2',(bd6.DEP_DELAY**2)\n",
    ").withColumn('DepD_Distance',(bd6.DEP_DELAY * bd6.DISTANCE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
