{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Modelo de Regresión Múltiple (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from pyspark import SparkContext\n",
    "#sc = SparkContext()\n",
    "#from pyspark.sql import SQLContext\n",
    "#sqlContext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bd5 = sqlContext.read.format(\n",
    "    \"com.databricks.spark.csv\"\n",
    ").option(\"header\", \"true\").load(\"bd5.csv\", inferSchema=True)\n",
    "sqlContext.registerDataFrameAsTable(bd5, \"bd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "bd5 = bd5.withColumn('Horario1',(bd5.Horario==1) \n",
    ").withColumn('Horario2',(bd5.Horario==2) \n",
    ").withColumn('Horario3',(bd5.Horario==3))\n",
    "\n",
    "# Términos cuadráticos añadidos manualmente\n",
    "bd5 = bd5.withColumn('DepDelay2',(bd5.DepDelay**2)\n",
    ").withColumn('DepD_Distance',(bd5.DepDelay * bd5.Distance)) \n",
    "\n",
    "a1  = VectorAssembler(\n",
    "    inputCols=['DepDelay','Distance','DayOfWeek',\n",
    "               'CRSDepTime','Horario1','Horario2',\n",
    "               'Horario3','DepDelay2','DepD_Distance'],\n",
    "    outputCol='features')\n",
    "\n",
    "bd6 = a1.transform(bd5).select(col(\"ArrDelay\").alias(\"label\"),'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/spark/python/pyspark/ml/regression.py:123: UserWarning: weights is deprecated. Use coefficients instead.\n",
      "  warnings.warn(\"weights is deprecated. Use coefficients instead.\")\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "lr = LinearRegression()\n",
    "model = lr.fit(bd6)\n",
    "pred = model.transform(bd6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.635889634541887 [1.05553557286,-0.00289488941365,0.135668773288,0.00144922041931,-0.242298226852,1.62235576514,0.159579377181,-1.79458480022e-05,-2.10428631003e-05]\n",
      "0.9178062697891254\n"
     ]
    }
   ],
   "source": [
    "print(model.intercept,model.coefficients)\n",
    "print(RegressionEvaluator(metricName=\"r2\").evaluate(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de variables y Regularización\n",
    "\n",
    "$\\sum{V(Y_i,f(X_i))} +\\lambda C(f)$\n",
    "\n",
    "En regresión lineal: \n",
    "\n",
    "$ f(X_i) = \\beta_0 + \\beta_1 X_{1i} + ... \\beta_p X_{pi}$\n",
    "\n",
    "$\\sum{(Y_i - f(X_i))^2} +\\lambda \\sum{\\beta^\\alpha} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regParam=0, sin penalización (OLS).\n",
    "\n",
    "elasticNetParam = 0, penalización L2 (Ridge). \n",
    "\n",
    "elasticNetParam = 1, penalización L1 (Lasso)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/spark/python/pyspark/ml/regression.py:123: UserWarning: weights is deprecated. Use coefficients instead.\n",
      "  warnings.warn(\"weights is deprecated. Use coefficients instead.\")\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(\n",
    "    maxIter=5, \n",
    "    regParam=5.0,\n",
    "    elasticNetParam=0.0,\n",
    "    solver=\"normal\")\n",
    "model = lr.fit(bd6)\n",
    "pred = model.transform(bd6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.6293446782818521 [0.779667508841,-0.0053345412431,0.24260292539,0.00231370712626,-1.16255761132,1.03064452132,0.0555277791927,6.76631283342e-05,0.000140493731922]\n",
      "0.903221414577995\n"
     ]
    }
   ],
   "source": [
    "print(model.intercept,model.coefficients)\n",
    "print(RegressionEvaluator(metricName=\"r2\").evaluate(pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('features', 'vector')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd6.select('features').dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/spark/python/pyspark/ml/regression.py:123: UserWarning: weights is deprecated. Use coefficients instead.\n",
      "  warnings.warn(\"weights is deprecated. Use coefficients instead.\")\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(\n",
    "    maxIter=5, \n",
    "    regParam=0.7,\n",
    "    elasticNetParam=1.0,\n",
    "    solver=\"auto\")\n",
    "model = lr.fit(bd6)\n",
    "pred = model.transform(bd6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2946644725630456 [0.869003269943,-0.00710768434873,0.0,0.000116522843855,0.0,0.0,0.0,-1.67295913798e-05,9.73290986538e-05]\n",
      "0.909270946443443\n"
     ]
    }
   ],
   "source": [
    "print(model.intercept,model.coefficients)\n",
    "print(RegressionEvaluator(metricName=\"r2\").evaluate(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿La estandaricación de las variables es necesaria?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/spark/python/pyspark/ml/regression.py:123: UserWarning: weights is deprecated. Use coefficients instead.\n",
      "  warnings.warn(\"weights is deprecated. Use coefficients instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8780392155255115 (9,[0,1,8],[0.873087274085,-0.00659023376409,9.56286564526e-05])\n",
      "0.9103469157085913\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(\n",
    "    maxIter=5, \n",
    "    regParam=1.0,\n",
    "    elasticNetParam=1.0,\n",
    "    solver=\"auto\",\n",
    "    standardization=True,\n",
    "    featuresCol = \"features\" ) \n",
    "model = lr.fit(bd6)\n",
    "pred = model.transform(bd6)\n",
    "print(model.intercept,model.coefficients)\n",
    "print(RegressionEvaluator(metricName=\"r2\").evaluate(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/spark/python/pyspark/ml/regression.py:123: UserWarning: weights is deprecated. Use coefficients instead.\n",
      "  warnings.warn(\"weights is deprecated. Use coefficients instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8246622701084778 [0.867109334427,-0.00721589949825,0.0,0.00126658111863,0.0,0.0,0.0,-7.62140637153e-05,0.000111806161815]\n",
      "0.9067726238943679\n"
     ]
    }
   ],
   "source": [
    "lr2 = LinearRegression(\n",
    "    maxIter=5, \n",
    "    regParam=0.7,\n",
    "    elasticNetParam=1.0,\n",
    "    solver=\"auto\",\n",
    "    standardization=False,\n",
    "    featuresCol = \"features\" ) \n",
    "model = lr2.fit(bd6)\n",
    "pred = model.transform(bd6)\n",
    "print(model.intercept,model.coefficients)\n",
    "print(RegressionEvaluator(metricName=\"r2\").evaluate(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__Estandarizar las variables__ nos ayuda a escalar los coeficientes del modelo a magnitudes comparables. Sin la estandarización la penalización se basa en los coeficientes brutos."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
